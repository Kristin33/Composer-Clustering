{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "auto_encoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kristin33/Composer-Clustering/blob/master/auto_encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlxA9TTsJW8E",
        "colab_type": "code",
        "outputId": "fb7b9fff-1b4b-4fbf-e372-870d04a6927a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# get the dataset from git\n",
        "!git clone https://github.com/Kristin33/Composer-Clustering\n",
        "\n",
        "%cd Composer-Clustering"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Composer-Clustering' already exists and is not an empty directory.\n",
            "/content/Composer-Clustering\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHwiki-XnGaR",
        "colab_type": "code",
        "outputId": "1adab023-9545-4009-96fe-03961b0ae2ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "!pip install pretty_midi\n",
        "\n",
        "import os, sys\n",
        "import pretty_midi\n",
        "import librosa, librosa.display\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "from scipy import stats\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pretty_midi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/82/ee67696b85ca3be267c67a46595545e719eec677dcd94e3cf827db833fb8/pretty_midi-0.2.8.tar.gz (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from pretty_midi) (1.18.2)\n",
            "Collecting mido>=1.1.16\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/0a/81beb587b1ae832ea6a1901dc7c6faa380e8dd154e0a862f0a9f3d2afab9/mido-1.2.9-py2.py3-none-any.whl (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pretty_midi) (1.12.0)\n",
            "Building wheels for collected packages: pretty-midi\n",
            "  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty-midi: filename=pretty_midi-0.2.8-cp36-none-any.whl size=5590819 sha256=267a3839f51fd14755b67b39ce018fe6c14478fd93508fa4e9e7ccb86c8d946f\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/e7/6b/70eb5879f7dbcb4f44fee735a61d6298f9e082be8538b52422\n",
            "Successfully built pretty-midi\n",
            "Installing collected packages: mido, pretty-midi\n",
            "Successfully installed mido-1.2.9 pretty-midi-0.2.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGwGtjRVFnHm",
        "colab_type": "text"
      },
      "source": [
        "# Data directories and experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ver8_nDOixPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# directory variables \n",
        "\n",
        "alkan_dir = \"alkan_(c)contributors-kunstderfuge/\"\n",
        "bach_dir = \"bach_lute_(c)contributors-kunstderfuge/\"\n",
        "dandrieu_dir = \"dandrieu_(c)contributors-kunstderfuge/\"\n",
        "dvorak_dir = \"dvorak_(c)contributors-kunstderfuge/\"\n",
        "scriabin_dir = \"scriabin_(c)contributors-kunstderfuge/\"\n",
        "byrd_dir = \"byrd_(c)contributors-kunstderfuge/\"\n",
        "faure_dir = \"faure_(c)contributors-kunstderfuge/\"\n",
        "buxtehude_dir = \"buxtehude_(c)contributors-kunstderfuge/\"\n",
        "beethoven_dir = \"beethoven_iii_(c)contributors-kunstderfuge/\"\n",
        "schumann_dir = \"schumann_(c)contributors-kunstderfuge/\"\n",
        "scriabin_dir = \"scriabin_(c)contributors-kunstderfuge/\"\n",
        "shostakovich_dir = \"shostakovich_(c)contributors-kunstderfuge/\"\n",
        "soler_dir = \"soler_(c)contributors-kunstderfuge/\"\n",
        "\n",
        "train_comps = [bach_dir, beethoven_dir]\n",
        "test_comps = [scriabin_dir, buxtehude_dir, byrd_dir]\n",
        "\n",
        "\n",
        "alkan_csv = \"alkan_all.csv\"\n",
        "bach_csv = \"bach_all.csv\"\n",
        "beethoven_csv = \"beethoven_all.csv\"\n",
        "brahms_csv = \"brahms_all.csv\"\n",
        "buxtehude_csv = \"buxtehude_all.csv\"\n",
        "byrd_csv = \"byrd_all.csv\"\n",
        "chopin_csv = \"chopin_all.csv\"\n",
        "dandrieu_csv = \"dandrieu_all.csv\"\n",
        "dvorak_csv = \"dvorak_all.csv\"\n",
        "faure_csv = \"faure_all.csv\"\n",
        "handel_csv = \"handel_all.csv\"\n",
        "haydn_csv = \"haydn_all.csv\"\n",
        "mozart_csv = \"mozart_all.csv\"\n",
        "scarlatti_csv = \"scarlatti_all.csv\"\n",
        "schubert_csv = \"schubert_all.csv\"\n",
        "schumann_csv = \"schumann_all.csv\"\n",
        "scriabin_csv = \"scriabin_all.csv\"\n",
        "shostakovich_csv = \"shostakovich_all.csv\"\n",
        "soler_csv = \"soler_all.csv\"\n",
        "\n",
        "train_csv_comps = [alkan_csv, bach_csv, beethoven_csv,\n",
        "                   brahms_csv, buxtehude_csv, byrd_csv, \n",
        "                   chopin_csv, dandrieu_csv, dvorak_csv,\n",
        "                   faure_csv, handel_csv, haydn_csv,\n",
        "                   mozart_csv, scarlatti_csv, schubert_csv,\n",
        "                  schumann_csv, scriabin_csv, shostakovich_csv, soler_csv]\n",
        "test_csv_comps = [alkan_csv, bach_csv, beethoven_csv,\n",
        "                   brahms_csv]\n",
        "                  # , buxtehude_csv, byrd_csv, \n",
        "                  #  chopin_csv, dandrieu_csv, dvorak_csv,\n",
        "                  #  faure_csv, handel_csv, haydn_csv,\n",
        "                  #  mozart_csv, scarlatti_csv, schubert_csv,\n",
        "                  # schumann_csv, scriabin_csv, shostakovich_csv, soler_csv]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WlR9UwuGS2s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "ec8292ed-eb84-41ea-d43a-0081b5fccd8e"
      },
      "source": [
        "# test_comps = [scriabin_dir, buxtehude_dir, byrd_dir]\n",
        "f1_e1 = [dandrieu_dir, soler_dir]\n",
        "f1_e2 = [dvorak_dir, schumann_dir]\n",
        "f1_e3 = [buxtehude_dir, faure_dir]\n",
        "f1_e4 = [scriabin_dir, byrd_dir]\n",
        "# f1_e5 = [shostakovich_dir, brahms_dir]\n",
        "# f1_e6 = [chopin_dir, debussy_dir]\n",
        "# f1_e7 = [schubert_dir, alkan_dir]\n",
        "# f1_e8 = [handel_dir, mozart_dir]\n",
        "# f1_e9 = [haydn_dir, beethoven_dir]\n",
        "# f1_e10 = [scarlatti_dir, bach_dir]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-5ecd5ce7854f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mf1_e3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbuxtehude_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaure_dir\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf1_e4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mscriabin_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbyrd_dir\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mf1_e5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mshostakovich_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrahms_dir\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mf1_e6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchopin_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebussy_dir\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mf1_e7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mschubert_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malkan_dir\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'brahms_dir' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ1PeUDjyKVE",
        "colab_type": "text"
      },
      "source": [
        "# Fetch Data Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ekl8ZHAiHD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "===========================================================\n",
        "Get the piano roll encoding of midi files \n",
        "===========================================================\n",
        "\n",
        "Attempt of using autoencoders to encode the pianoroll representation\n",
        "into a lower dimension latent representation. \n",
        "\n",
        "currently, the input of the piano roll is of dimension 1280000\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def get_piano_roll_matrix(midi_data, start_pitch, end_pitch, fs=50, draw=False):\n",
        "    # roll = midi_data.get_piano_roll(fs)[start_pitch:end_pitch]\n",
        "    matrix = midi_data.get_piano_roll(fs)[:, :10000]\n",
        "    # print(matrix[:, 30:40])\n",
        "    # print(matrix.shape)\n",
        "\n",
        "    if draw: \n",
        "      librosa.display.specshow(matrix,\n",
        "            hop_length=1, sr=fs, x_axis='time', y_axis='cqt_note',\n",
        "            fmin=pretty_midi.note_number_to_hz(start_pitch))\n",
        "    return np.array(matrix).flatten()\n",
        "\n",
        "# input: an array of \n",
        "def get_test_data(test_comps):\n",
        "    \n",
        "    data_dir = \"New_Data_Selection/\"\n",
        "\n",
        "    comp_data, comp_label = [], []\n",
        "\n",
        "    for idx, test_comp in enumerate(test_comps):\n",
        "      print(test_comp)\n",
        "      tmp_data, tmp_label = [], []\n",
        "      for filename in os.listdir(data_dir + test_comp):\n",
        "          \n",
        "          if \".mid\" in filename or \".MID\" in filename:\n",
        "              midi_data = pretty_midi.PrettyMIDI(data_dir + test_comp + filename)\n",
        "              l = midi_data.get_end_time()\n",
        "              # scale the sampling frequency by the length of data, so the picture is \n",
        "              # of the same size 128 * 10000\n",
        "              fs = 50 * (10000/(l * 50 - 1))\n",
        "              roll = []\n",
        "              roll.append(get_piano_roll_matrix(midi_data,36,108,fs=fs,draw=False))\n",
        "              tmp = tmp_data + roll\n",
        "              if (len(np.array(tmp).shape) != 2):\n",
        "                continue\n",
        "              tmp_data.append(roll[0])\n",
        "              tmp_label.append(idx)\n",
        "      comp_data.extend(tmp_data)\n",
        "      comp_label.extend(tmp_label)\n",
        "\n",
        "\n",
        "    data = np.array(comp_data)\n",
        "    labels = np.array(comp_label)\n",
        "\n",
        "    return data, labels\n",
        "\n",
        "\n",
        "def get_train_data(train_comps):\n",
        "    \n",
        "    data_dir = \"New_Data_Selection/\"\n",
        "\n",
        "    comp_data, comp_label = [], []\n",
        "\n",
        "    for idx, train_comp in enumerate(train_comps):\n",
        "      print(train_comp)\n",
        "      tmp_data, tmp_label = [], []\n",
        "      for filename in os.listdir(data_dir + train_comp):\n",
        "          if \".mid\" in filename or \".MID\" in filename:\n",
        "              midi_data = pretty_midi.PrettyMIDI(data_dir + train_comp + filename)\n",
        "              l = midi_data.get_end_time()\n",
        "              # scale the sampling frequency by the length of data, so the picture is \n",
        "              # of the same size 128 * 10000\n",
        "              fs = 50 * (10000/(l * 50 - 1))\n",
        "              roll = []\n",
        "              roll.append(get_piano_roll_matrix(midi_data,36,108,fs=fs,draw=False))\n",
        "              tmp = tmp_data + roll\n",
        "              if (len(np.array(tmp).shape) != 2):\n",
        "                continue\n",
        "              tmp_data.append(roll[0])\n",
        "              tmp_label.append(idx)\n",
        "      comp_data.extend(tmp_data)\n",
        "      comp_label.extend(tmp_label)\n",
        "\n",
        "    data = np.array(comp_data)\n",
        "    labels = np.array(comp_label)\n",
        "\n",
        "    return data, labels\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYbUW-fIVVcY",
        "colab_type": "text"
      },
      "source": [
        "# Fetch data: old csv files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6JopWuMVaFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_csv_train_data(train_csv_comps):\n",
        "    \n",
        "    data_dir = \"0229_Experiment/csv/\"\n",
        "\n",
        "    composer_data = np.empty((0, 776))\n",
        "    composer_label = np.empty((0,))\n",
        "\n",
        "    for filename in train_csv_comps:\n",
        "        data = np.genfromtxt(data_dir + filename, delimiter=',', \n",
        "                             usecols=np.arange(1,777), encoding=\"latin1\")\n",
        "        # get rid of the top row with feature names\n",
        "        data = data[1:,:]\n",
        "        # standarize the data\n",
        "        data = stats.zscore(data)\n",
        "        data = np.nan_to_num(data)\n",
        "\n",
        "        composer_data = np.append(composer_data, data, axis=0)\n",
        "        composer_label = np.append(composer_label, np.zeros((data.shape[0],)), axis=0)\n",
        "\n",
        "    data = composer_data\n",
        "    labels = composer_label\n",
        "\n",
        "    return data, labels\n",
        "\n",
        "def get_csv_test_data(test_csv_comps):\n",
        "    \n",
        "    data_dir = \"0229_Experiment/csv/\"\n",
        "\n",
        "    composer_data = np.empty((0, 776))\n",
        "    composer_label = np.empty((0,))\n",
        "    \n",
        "\n",
        "    for idx, filename in enumerate(test_csv_comps):\n",
        "        print(filename)\n",
        "        data = np.genfromtxt(data_dir + filename, delimiter=',', \n",
        "                             usecols=np.arange(1,777), encoding='latin1')\n",
        "        # get rid of the top row with feature names\n",
        "        data = data[1:,:]\n",
        "        # standarize the data\n",
        "        data = stats.zscore(data)\n",
        "        data = np.nan_to_num(data)\n",
        "\n",
        "        composer_data = np.append(composer_data, data, axis=0)\n",
        "        composer_label = np.append(composer_label, np.ones((data.shape[0],)) * idx, axis=0)\n",
        "\n",
        "    data = composer_data\n",
        "    labels = composer_label\n",
        "\n",
        "    return data, labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC4WxWEFZbHA",
        "colab_type": "text"
      },
      "source": [
        "# Fetch training data for autoencoders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELSj6hsLJyjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "===========================================================\n",
        "Auto encoders\n",
        "===========================================================\n",
        "\n",
        "Attempt of using autoencoders to encode the pianoroll representation\n",
        "into a lower dimension latent representation. \n",
        "\n",
        "currently, the input of the piano roll is of dimension 1280000\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "# from __future__ import print_function\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.regularizers import l1\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras import regularizers\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RImmzPhPM1bB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train) = get_train_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "\n",
        "\n",
        "print(x_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BfwVqoByVxI",
        "colab_type": "text"
      },
      "source": [
        "# Construct Model and Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq2ZWb4rKKMx",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "def get_ae(input_size):\n",
        "  # if using piano roll, input_size = 1280000, if jSymbolic feature, size is 776 \n",
        "  hidden_size = 128\n",
        "  code_size = 32\n",
        "\n",
        "  input_img = Input(shape=(input_size,))\n",
        "  hidden_1 = Dense(hidden_size, activation='relu')(input_img)\n",
        "  code = Dense(code_size, activation='relu')(hidden_1)\n",
        "  hidden_2 = Dense(hidden_size, activation='relu')(code)\n",
        "  output_img = Dense(input_size, activation='sigmoid')(hidden_2)\n",
        "\n",
        "\n",
        "  # input_img = Input(shape=(input_size,))\n",
        "  # encoded = Dense(128, activation='relu', activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
        "  # encoded = Dense(64, activation='relu', activity_regularizer=regularizers.l1(10e-5))(encoded)\n",
        "  # encoded = Dense(32, activation='relu', activity_regularizer=regularizers.l1(10e-5))(encoded)\n",
        "  # code = Dense(8, activation='relu', activity_regularizer=regularizers.l1(10e-5))(encoded)\n",
        "  # decoded = Dense(32, activation='relu')(code)\n",
        "  # decoded = Dense(64, activation='relu')(decoded)\n",
        "  # decoded = Dense(128, activation='relu')(decoded)\n",
        "  # output_img = Dense(input_size, activation='sigmoid')(decoded)\n",
        "\n",
        "\n",
        "  autoencoder = Model(input_img, output_img)\n",
        "  autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "  autoencoder_half = Model(input_img, code)\n",
        "\n",
        "  return autoencoder, autoencoder_half\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi5gqPUFB50v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# alternative model: Convolutional Autoencoders\n",
        "from keras.layers import Input, Dense, Reshape, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "def get_conv_ae(input_size):\n",
        "  # if using piano roll, input_size = 1280000, if jSymbolic feature, size is 776 \n",
        "\n",
        "  input_img = Input(shape=(120, 9992, 1))\n",
        "\n",
        "  x = Conv2D(16, (5, 5), activation='relu', padding='same')(input_img)\n",
        "  x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "  x = Conv2D(8, (5, 5), activation='relu', padding='same')(x)\n",
        "  x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "  x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "  x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "  x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "  encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "  # at this point the representation is (8, 625, 8) i.e. 400000-dimensional\n",
        "  tmp = Reshape((40000,), input_shape=(8, 625, 8))(encoded)\n",
        "  hidden_1 = Dense(128, activation='relu')(tmp)\n",
        "  code = Dense(32, activation='relu')(hidden_1)\n",
        "  # code should have dimension 32? \n",
        "  hidden_2 = Dense(128, activation='relu')(code)\n",
        "  hidden_3 = Dense(40000, activation='relu')(hidden_2)\n",
        "  tmp = Reshape((8, 625, 8), input_shape=(40000,))(hidden_3)\n",
        "\n",
        "  x = Conv2D(8, (3, 3), activation='relu', padding='same')(tmp)\n",
        "  x = UpSampling2D((2, 2))(x)\n",
        "  x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "  x = UpSampling2D((2, 2))(x)\n",
        "  x = Conv2D(8, (5, 5), activation='relu', padding='same')(x)\n",
        "  x = UpSampling2D((2, 2))(x)\n",
        "  x = Conv2D(16, (5, 5), activation='relu')(x)\n",
        "  x = UpSampling2D((2, 2))(x)\n",
        "  decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "  autoencoder = Model(input_img, decoded)\n",
        "  autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "  return autoencoder\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xZrknt4CmyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train autoencoder \n",
        "\n",
        "\n",
        "# if using piano roll, input_size = 1280000, if jSymbolic feature, size is 776 \n",
        "input_size = 1280000\n",
        "# autoencoder, autoencoder_half = get_ae(input_size)\n",
        "# autoencoder_train = autoencoder.fit(x_train, x_train, epochs=10)\n",
        "\n",
        "autoencoder = get_conv_ae(input_size)\n",
        "# x_train = np.reshape(x_train, (len(x_train), 1, 128, 10000))\n",
        "a = np.reshape(x_train, (len(x_train), 128, 10000, 1))\n",
        "x_train_new = a[:, 8:, 8:, :]\n",
        "autoencoder_train = autoencoder.fit(x_train_new, x_train_new,\n",
        "                nb_epoch=100)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ2lsFic45WO",
        "colab_type": "text"
      },
      "source": [
        "# Parameter Search (tbd)\n",
        "\n",
        "The parameters that we want to tune: epoches, hidden layer size, and code size. \n",
        "\n",
        "Model variation that we want to try: sparse autoendoers, deep autoencoders, convolutional autoencoders "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXhKf2wN_aUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.model_selection import GridSearchCV\n",
        "# from sklearn.pipeline import Pipeline\n",
        "\n",
        "# auto = Pipeline([\n",
        "#     ('auto',autoencoder)\n",
        "# ])\n",
        "# auto.get_params()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QEPJ4ai5Un9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# # batch_size = [10, 20, 40, 60, 80, 100]\n",
        "# hidden_size = [64, 128, 256]\n",
        "# code_size = [32, 64, 128]\n",
        "# epochs = [4, 10, 50, 100]\n",
        "# # param_grid = dict(batch_size=batch_size, epoch=epochs)\n",
        "# param_grid = dict(hidden_size=hidden_size, code_size=code_size, epoch=epochs)\n",
        "# grid = GridSearchCV(estimator=auto, param_grid=param_grid, n_jobs=1, scoring=\"accuracy\")\n",
        "# grid_result = grid.fit(x_train, x_train)\n",
        "# # summarize results\n",
        "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKbdNnKUFb7v",
        "colab_type": "text"
      },
      "source": [
        "# Fetch testing data and cluster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuasitYUvNud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def get_latent_representation(expr):\n",
        "\n",
        "  test_comps = expr\n",
        "  # test_comps = [scriabin_dir, buxtehude_dir, byrd_dir]\n",
        "\n",
        "  (x_test, y_test) = get_test_data(test_comps)\n",
        "  # if using piano roll, x_test.shape should be n * 1280000, n is the number of \n",
        "  # test samples. If using csv, x_test.shape should be n * 776\n",
        "  print(x_test.shape)\n",
        "  x_test = x_test.astype('float32') / 255.0\n",
        "  x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "  # using autoencoders\n",
        "\n",
        "  # using convolutional autoencoder, needs to reshape data (input and output)\n",
        "  autoencoder_half = Model(inputs=autoencoder.input, outputs=autoencoder.layers[11].output)\n",
        "  a = np.reshape(x_test, (len(x_test), 128, 10000, 1))\n",
        "  x_test_new = a[:, 8:, 8:, :]\n",
        "  pred = autoencoder_half.predict(x_test_new)\n",
        "  print(pred.shape)\n",
        "\n",
        "  # just using the matrix data to cluster\n",
        "  # pred = x_test\n",
        "  # print(pred.shape)\n",
        "\n",
        "  data = pred\n",
        "  labels = y_test\n",
        "\n",
        "  np.random.seed(42)\n",
        "\n",
        "  # X_digits, y_digits = load_digits(return_X_y=True)\n",
        "  # print(\"X_digits shape: {}\".format(X_digits.shape))\n",
        "  # print(\"y_digits shape: {}\".format(y_digits.shape))\n",
        "  # data = scale(X_digits)\n",
        "  print(\"data shape: {}\".format(data.shape))\n",
        "\n",
        "  n_samples, n_features = data.shape\n",
        "  n_digits = len(np.unique(labels))\n",
        "  # n_digits = len(np.unique(y_digits))\n",
        "  # labels = y_digits\n",
        "\n",
        "\n",
        "  print(\"n_composers: %d, \\t n_test_samples %d, \\t n_features %d\"\n",
        "        % (n_digits, n_samples, n_features))\n",
        "  \n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkBc3x5sNnUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pred\n",
        "labels = y_test\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# X_digits, y_digits = load_digits(return_X_y=True)\n",
        "# print(\"X_digits shape: {}\".format(X_digits.shape))\n",
        "# print(\"y_digits shape: {}\".format(y_digits.shape))\n",
        "# data = scale(X_digits)\n",
        "print(\"data shape: {}\".format(data.shape))\n",
        "\n",
        "n_samples, n_features = data.shape\n",
        "n_digits = len(np.unique(labels))\n",
        "# n_digits = len(np.unique(y_digits))\n",
        "# labels = y_digits\n",
        "\n",
        "\n",
        "print(\"n_composers: %d, \\t n_test_samples %d, \\t n_features %d\"\n",
        "      % (n_digits, n_samples, n_features))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPkGK2KKfeVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import scale\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTJhcV03ylJB",
        "colab_type": "text"
      },
      "source": [
        "# Run KMeans"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFvVnvkNOVLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# experiment is a list of composer directories that we are \n",
        "# fetching test data from\n",
        "def bench_k_means(estimator, name, data, experiment):\n",
        "    data = get_latent_representation(experiment)\n",
        "\n",
        "    t0 = time()\n",
        "    estimator.fit(data)\n",
        "    print(labels)\n",
        "    print(estimator.labels_)\n",
        "    print('%-9s\\t%.2fs\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t'\n",
        "          % (name, (time() - t0), estimator.inertia_,\n",
        "             metrics.homogeneity_score(labels, estimator.labels_),\n",
        "             metrics.completeness_score(labels, estimator.labels_),\n",
        "             metrics.v_measure_score(labels, estimator.labels_),\n",
        "             metrics.adjusted_rand_score(labels, estimator.labels_),\n",
        "             metrics.adjusted_mutual_info_score(labels,  estimator.labels_)))\n",
        "            #  metrics.silhouette_score(data, estimator.labels_,\n",
        "            #                           metric='euclidean')))\n",
        "    expr_name = \"_\".join(experiment)\n",
        "    with open(expr_name + \".txt\", \"w\") as f:\n",
        "      f.write(\"experiment: \" + expr_name + \"\\n\")\n",
        "      f.write(\"algorithm: convolutional autoencoders \\n\")\n",
        "      f.write(\"training data: bach lute and beethoven piano concertos(26) \\n\")\n",
        "      f.write(\"latent representation: dimension 32 vector \\n\")\n",
        "      f.write('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette\\n')\n",
        "      f.write('%-9s\\t%.2fs\\t%i\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t%.3f\\t'\n",
        "          % (name, (time() - t0), estimator.inertia_,\n",
        "             metrics.homogeneity_score(labels, estimator.labels_),\n",
        "             metrics.completeness_score(labels, estimator.labels_),\n",
        "             metrics.v_measure_score(labels, estimator.labels_),\n",
        "             metrics.adjusted_rand_score(labels, estimator.labels_),\n",
        "             metrics.adjusted_mutual_info_score(labels,  estimator.labels_)))\n",
        "      f.write(82 * \"_\" + \"\\n\")\n",
        "      f.write(np.array2string(labels))\n",
        "      f.write(\"\\n\")\n",
        "      f.write(np.array2string(estimator.labels_))\n",
        "\n",
        "expr = f1e1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQNWB6_XDpSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "expr_list = [f1_e1, f1_e2, f1_e3, f1_e4]\n",
        "            #  f1_e5, f1_e6, f1_e7, f1_e8, f1_e9, f1_e10]\n",
        "\n",
        "# expr_list is a list of experiments, experiment is a list of composition directories\n",
        "def run_batch_experiments(expr_list):\n",
        "  for expr in expr_list:\n",
        "\n",
        "    print(\"\\n {} \\n\".format(*expr))\n",
        "    print(82 * '_')\n",
        "    print('init\\t\\ttime\\tinertia\\thomo\\tcompl\\tv-meas\\tARI\\tAMI\\tsilhouette')\n",
        "    bench_k_means(KMeans(init='k-means++', n_clusters=n_digits, n_init=10),\n",
        "                  name=\"k-means++\", data=data, experiment=expr)\n",
        "\n",
        "    bench_k_means(KMeans(init='random', n_clusters=n_digits, n_init=10),\n",
        "                  name=\"random\", data=data, experiment=expr)\n",
        "\n",
        "    # in this case the seeding of the centers is deterministic, hence we run the\n",
        "    # kmeans algorithm only once with n_init=1\n",
        "    pca = PCA(n_components=n_digits).fit(data)\n",
        "    bench_k_means(KMeans(init=pca.components_, n_clusters=n_digits, n_init=1),\n",
        "                  name=\"PCA-based\",\n",
        "                  data=data, experiment=expr)\n",
        "    print(82 * '_')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2NrZKjBBUYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF_IbSWa6dm-",
        "colab_type": "text"
      },
      "source": [
        "# Visualization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWdlxu-E6cxU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #############################################################################\n",
        "# Visualize the results on PCA-reduced data\n",
        "\n",
        "reduced_data = PCA(n_components=2).fit_transform(data)\n",
        "kmeans = KMeans(init='k-means++', n_clusters=n_digits, n_init=10)\n",
        "kmeans.fit(reduced_data)\n",
        "\n",
        "# Step size of the mesh. Decrease to increase the quality of the VQ.\n",
        "h = .02     # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
        "\n",
        "# Plot the decision boundary. For that, we will assign a color to each\n",
        "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
        "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "\n",
        "# Obtain labels for each point in mesh. Use last trained model.\n",
        "Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n",
        "# Put the result into a color plot\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.figure(1)\n",
        "plt.clf()\n",
        "plt.imshow(Z, interpolation='nearest',\n",
        "           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
        "           cmap=plt.cm.Paired,\n",
        "           aspect='auto', origin='lower')\n",
        "\n",
        "# draw the data points \n",
        "# TODO: currently these data points are all black, want to color them by \n",
        "# the true composers\n",
        "plt.plot(reduced_data[:, 0], reduced_data[:, 1], 'k.', markersize=2)\n",
        "\n",
        "\n",
        "# Plot the centroids as a white X\n",
        "centroids = kmeans.cluster_centers_\n",
        "plt.scatter(centroids[:, 0], centroids[:, 1],\n",
        "            marker='x', s=169, linewidths=3,\n",
        "            color='w', zorder=10)\n",
        "plt.title('K-means clustering on the latent representation of compositions (PCA-reduced data)\\n'\n",
        "          'Centroids are marked with white cross')\n",
        "plt.xlim(x_min, x_max)\n",
        "plt.ylim(y_min, y_max)\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1CA0hbzfZ7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}